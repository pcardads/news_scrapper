# News Scrapper com Python, Selenium e outras bibliotecas
## ‚û°Ô∏è Fazendo login
A primeira fun√ß√£o do nosso sistema √© ```def login_twitter```, que serve para o usu√°rio inserir as credenciais de acesso ao X. √â uma fun√ß√£o que espera receber tr√™s argumentos: driver, username e password.

Ela √© composta por um bloco **try/except**, que tentar√° acessar a p√°gina principal da rede social X, encontrar os campos para preenchimento do nome de usu√°rio com senha e acessar o feed de not√≠cias. 

Agora, vamos analisar algumas linhas e blocos importantes dessa fun√ß√£o.

```time.sleep(5)```
üîéEsta espera √© importante para garantir que tanto o DOM b√°sico como os elementos JavaScript, CSS e din√¢micos estejam carregados. ***DOM (Document Object Model)*** √© a representa√ß√£o da p√°gina web que estamos acessando na mem√≥ria do navegador. 

Apenas ela n√£o √© suficiente para termos certeza que um site complexo, como o X, que possui os campos de login criados dinamicamente, esteja pronto para o scrapping.

```wait = WebDriverWait(driver, 20)```
üîéAqui, criamos um objeto de espera inteligente que serve para verificar repetidamente uma condi√ß√£o. Uma vez que ela √© atendida, o objeto "para".

1. Encontrar campo username e inserir as informa√ß√µes do usu√°rio;
Aqui, criamos uma lista com *seletores CSS*, que ser√° percorrida atrav√©s do loop **for**. O loop vai parar assim que o Selenium encontrar um elemento na p√°gina que contenha exatamente os mesmos valores e atributos fornecidos.

Por exemplo, ```'input[name="text"]'``` localiza um elemento <input> que possui o atributo *name* com o valor exato "password". ```'input[data-testid="ocfEnterTextTextInput"]'``` √© criado especificamente para automa√ß√£o de testes, fornecendo um "gancho" est√°vel, que n√£o muda mesmo que o design ou a estrutura do backend sejam alterados.

Se ap√≥s a varredura feita no loop nada for encontrado, o usu√°rio √© avisado que o campo username n√£o foi encontrado, e a fun√ß√£o termina retornando False. Se o scrapper achar nosso campo, o seguinte bloco de c√≥digo ser√° executado:

```
    print(f'Campo sendo preenchido: username({username})')
    username_field.clear()
    username_field.send_keys(username)
    username_field.send_keys(Keys.RETURN)
    time.sleep(3)
```

*clear()* limpa algum placeholder que esteja presente no campo, *send_keys(username)* faz a inser√ß√£o dos caracteres enviados pelo usu√°rio e *send_keys(Keys.RETURN)* "pressiona" a tecla ENTER, do teclado.

2. Encontrar campo senha e inserir as informa√ß√µes do usu√°rio;
Esse trecho funciona de forma semelhante ao que foi constru√≠do para encontrar o campo username. Uma lista com seletores css √© criada para encontrar os elementos correspondentes √† senha. Os seletores aqui s√£o diferentes. ```'input[type="password"]'```, por exemplo, tem como principal caracter√≠stica o fato de esconder os caracteres digitados por pontinhos ou asteriscos quando a senha √© digitada.

3. Certificando sucesso do login
O √∫ltimo passo para que a fun√ß√£o esteja completa √© garantir que o login tenha sido realizado com sucesso. Para isso, tamb√©m criamos uma lista com seletores css que ser√° percorrida pelo loop for. A fun√ß√£o termina com a *Exception e*, que pode acontecer por problemas de conex√£o, do navegador ou outro erro inesperado.


## ‚û°Ô∏è Coletando os posts do perfil
Depois de fazer login, o programa deve acessar o perfil de not√≠cias escolhido, rolar a p√°gina e captar os textos e os coment√°rios de cada post. A fun√ß√£o anterior precisou ser feita porque o X n√£o permite o acesso aos coment√°rios sem um login. 


Passamos para a configura√ß√£o do Chrome atrav√©s de algumas op√ß√µes importantes:
‚úÖoptions.add_argument('--no-sandbox')
Desativa o "sandbox" de seguran√ßa do Chrome, que √© um recurso que isola os processos do navegador do resto do sistema, impedindo que sites maliciosos causem danos. Em muitos ambientes de servidor e cont√™ineres, as restri√ß√µes de permiss√µes do sistema entram em conflito com o sandbox, impedindo o navegador de iniciar. 

‚úÖoptions.add_argument('--disable-dev-shm-usage')
Navegadores baseados em Chromium usam o diret√≥rio de mem√≥ria compartilhada *dev-shm* para armazenar arquivos tempor√°rios. O tamanho padr√£o desse diret√≥rio pode ser muito pequeno, o que pode fazer com que o navegador trave. Este argumento instrui o navegador a usar o diret√≥rio /tmp, que geralmente tem mais espa√ßo dispon√≠vel.

‚úÖoptions.add_argument('--disable-blink-features=AutomationControlled')
Ao implementar essa linha de c√≥digo, desativamos um recurso espec√≠fico do motor de renderiza√ß√£o *Blink*, que permite que sites verifiquem a propriedade **navigator.webdriver** no JavaScript. Quando um navegador √© controlado pelo Selenium, navigator.webdriver geralmente retorna *true*. Ao desativar essa funcionalidade, a propriedade pode retornar *false*, fazendo com que o navegador pare√ßa n√£o estar automatizado.

‚úÖoptions.add_experimental_option("excludeSwitches", ["enable-automation"])
Aqui estamos simplesmente removendo o switch que faz aparecer a barra de notifica√ß√£o "O Chrome est√° sendo controlado por um software de teste automatizado". 

‚úÖoptions.add_experimental_option('useAutomationExtension', False)
E por fim pedimos que o Selenium n√£o use uma extens√£o de automa√ß√£o interna que ele normalmente injeta no navegador. A presen√ßa dessa extens√£o pode ser outro sinal para os sistemas de detec√ß√£o de que se trata de um bot.


Depois de fazer a instala√ß√£o do driver, adicionamos mais uma camada de prote√ß√£o contra detec√ß√£o de automa√ß√£o atrav√©s desta linha de c√≥digo:
```driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")```
**driver.execute_script()**: m√©todo do Selenium que permite executar um c√≥digo JavaScript direto no navegador.
**Object.defineProperty()**: fun√ß√£o em JavaScript que permite modificar as propriedades de um objeto.
**navigator**: o objeto que iremos alterar.
**webdriver**: propriedade do objeto navigator, que em geral retorna True, pois de fato ele est√° sendo utilizado.
**{get: () => undefined}**: acionamos essa parte justamente para mudar esse True quando o script do site tentar ler (get) as propriedades de navigator.webdriver.


‚ÄºÔ∏èAgora entramos no bloco *try* da nossa fun√ß√£o. A primeira verifica√ß√£o a ser feita √© se o login foi bem sucedido (lembrando que a fun√ß√£o *login_twitter* retorna um *bool*). Em caso negativo, *collecting_posts* retorna uma lista vazia. 

Se o login tiver dado certo, vamos acessar a url e extrair seu nome atrav√©s da fun√ß√£o **split**, que retorna uma lista. Dividimos a url pelas barras (/) e pegamos o √∫ltimo elemento, que corresponde ao nome do portal que estamos acessando [-1].


Em seguida, setamos as vari√°veis que ir√£o nortear nosso scrapper pelos posts. 
``collected_data = []``: uma lista de dicion√°rios que ir√° armazenar o c√≥digo da postagem, o nome do portal de not√≠cias, o texto do post e o texto dos coment√°rios.
``processed_posts = set()``: um conjunto que tem como principal objetivo evitar duplicatas. √â que quando rolarmos a p√°gina v√°rias vezes, os mesmos posts aparecer√£o, mas atrav√©s do set garantimos que apenas os posts com id ainda n√£o acessados sejam clicados.
``collected_posts = 0``: n√∫mero de posts coletados.
``scrollings = 0``: n√∫mero de rolagens na p√°gina.
``max_scrollings = 15``: n√∫mero m√°ximo permitido de rolagens.


O la√ßo principal determina que enquanto o n√∫mero de posts coletados for menor que o n√∫mero determinados na fun√ß√£o e o n√∫mero de rolagens na p√°gina for menor que o m√°ximo permitido os posts e coment√°rios ser√£o buscados.

```if not posts```: esse bloco ser√° executado enquanto a p√°gina n√£o carregar nenhum post. Note que se nenhum for encontrado at√© que o n√∫mero de rolagens m√°ximo permitido seja alcan√ßado nenhum dado ser√° exibido. O comando em JavaScript **"window.scrollTo(0, document.body.scrollHeight);"** serve para rolar a p√°gina at√© o final, j√° que em muitos casos somente ap√≥s fazer isso o conte√∫do ir√° aparecer. 


Agora, para cada post encontrado, iremos extrair o texto, criar ids √∫nicos para evitar as repeti√ß√µes e coletar coment√°rios. Antes, veja os seletores css utilizados:
‚úîÔ∏è *article[data-testid="tweet"]*: 'article' √© a tag HMTL que identifica cada tweet, e o que est√° dentro dos colchetes √© o atributo espec√≠fico que o X usa para eles.
‚úîÔ∏è *[data-testid="tweetText"]*: conte√∫do textual do tweet que estamos acessando.


### Stale Elements (StaleElementReferenceException)
Isso j√° aconteceu com todo mundo. Voc√™ liga o computador, espera a √°rea de trabalho carregar e clica no √≠cone que representa o atalho para algum programa. Ao clicar, o sistema avisa que o software n√£o pode ser executado porque foi exclu√≠do ou desinstalado. A exce√ß√£o ***StaleElementReferenceException*** acontece de uma forma semelhante.

Um "Stale Element" (Elemento Obsoleto ou Vencido) √© um elemento que o WebDriver encontrou com sucesso em um momento, mas que, por alguma raz√£o, n√£o est√° mais v√°lido ou anexado √† p√°gina no momento em que voc√™ tenta interagir com ele. Isso pode acontecer porque a p√°gina foi carregada, o elemento foi removido ou at√© porque o elemento foi alterado de forma din√¢mica pelo JavaScript. 

Temos diversas formas para evitar isso, como a **WebDriverWait**, que j√° falamos anteriormente. Al√©m disso, no nosso c√≥digo, cada post possui um index (ver linhas 170 e 183), que servir√£o para identificar cada post de forma individual. 

```post_id = f'{post_index}_{hash(post_text)}'```
O *post_id* √© uma string formada pelo *post_index*, que √© a posi√ß√£o dele na p√°gina; e pelo hash do *post_text*. O hash √© a representa√ß√£o em n√∫meros inteiros de algum objeto. Cada um deles ser√° armazenado no nosso set *processed_posts*. Assim, nosso la√ßo n√£o corre o risco de nos lan√ßar numa exce√ß√£o de Stale Element.

Na parte final desta fun√ß√£o, coletamos os coment√°rios (atrav√©s de uma outra fun√ß√£o cuja implementa√ß√£o iremos discutir a seguir) e fazemos o armazenamento dos conte√∫dos textuais na nossa lista de dicion√°rios **collected_data**. Caso ocorra algum problema, lan√ßamos uma exce√ß√£o para fechar nosso try, e no bloco *finally* realizamos o logoff e fechamos a p√°gina. 


## Detalhamento da coleta de coment√°rios
A fun√ß√£o ```collecting_comments``` foi colocada √† parte para organizar melhor o c√≥digo, deixando ele mais claro e menos complexo. Al√©m disso, podemos tratar de forma menos confusa poss√≠veis erros que possam acontecer nessa parte, evitando assim que o programa quebre por completo ao deixar tudo dentro de uma s√≥ fun√ß√£o. 

O funcionamento da fun√ß√£o √© simples: procuramos elementos clic√°veis na p√°gina que possuem o nome *status* na url. Para isso, utilizamos o seletor ```'a[href*="/status/"]'```. Em redes sociais como o X, normalmente esse seletor aponta para atualiza√ß√µes de status e postagens. Depois de abrir o post, salvamos em uma lista todos os elementos que achamos.

Agora iteramos sobre a lista criada pulando o primeiro elemento, que √© a postagem principal, e coletamos os coment√°rios. Extra√≠mos o texto do coment√°rio e adicionamos o conte√∫do na lista **comments** (que utilizamos na fun√ß√£o ```collecting_posts```). Por fim voltamos para a p√°gina inicial a fim de coletar os coment√°rios de mais posts.


## Processamento dos dados coletados
No m√≥dulo *processing.py* vamos utilizar algumas bibliotecas espec√≠ficas para analisar o sentimento dos coment√°rios que foram coletados, organizar os dados em um arquivo csv e apresent√°-los de forma organizada em tabelas.

### ```def clean text```
Aqui vamos fazer uma limpeza nos textos dos coment√°rios que coletamos, porque no geral eles podem vir com emojis, caracteres especiais e conte√∫dos de m√≠dia. Para isso, vamos utilizar as *express√µes regulares* atrav√©s da importa√ß√£o do m√≥dulo **re**.

```re.sub(r'https?://\S+|www\.\S+', '', text)```
Procura os caracteres http:// ou https:// seguidos por um ou mais caracteres que n√£o sejam espa√ßos em branco (S+); ou (|) urls que come√ßam com www; ```\.``` garante que estamos √† procura de um ponto literal. Os textos que corresponderem √† busca ser√£o substitu√≠dos por ```''```, ou seja, uma string vazia. ```text``` indica a vari√°vel que cont√©m o texto original.

```re.sub(r'\@\w+|\#', '', text)```
Aqui queremos eliminar as men√ß√µes. Para isso, utilizamos *\@* para procurar o caractere literal @ seguido de um ou mais (+) caracteres de palavra (w) que incluem letras, n√∫meros e o underscore (_) ou o caractere literal (#). 

```re.sub(r'[^a-zA-Z\d\s]', '', text, flags=re.A)```
Nessa parte nosso objetivo √© remover os caracteres especiais. O s√≠mbolo ^ nega tudo que estiver dentro dos colchetes. Ou seja, nossa express√£o vai encontrar e substituir por uma string vazia caracteres que n√£o sejam mai√∫sculos ou min√∫sculos, n√∫meros (\d) ou um espa√ßo em branco (\s). A flag ```re.A```, que tamb√©m pode ser ```re.ASCII```, faz com que *\s* corresponda somente a espa√ßos normais, tabs e quebras de linha, sem incluir outros caracteres de espa√ßo Unicode.

```re.sub(r'\s+', '', text)```
A express√£o acima serve para converter os espa√ßos em branco, tabs e quebras de linha em um espa√ßo simples.

### ```def saving_data(data, file_name='dados_coletados.csv')```
Nesta fun√ß√£o, vamos utilizar a biblioteca pandas para organizar em tabelas nossos dados coletados em ```def collecting_posts```. Como par√¢metros, temos 'data', que vai receber nosso dicion√°rio com coment√°rios, e um par√¢metro nomeado **file_name**, que cont√©m o nome do arquivo csv de sa√≠da desses dados.

Sem dados, a fun√ß√£o retorna None. Com dados, criamos nosso dataframe, a principal estrutura de dados da biblioteca pandas. √â uma tabela simples, com linhas e colunas. Primeiro criamos o dataframe, ```df = pd.DataFrame(data)```, passando como par√¢metro data, que √© exatamente nosso dicion√°rio ***collected_data***. A tabela est√° criada, e agora simplesmente aplicamos √†s informa√ß√µes contidas na coluna [comment_text] as formata√ß√µes que definimos na nossa fun√ß√£o *clen_text*: ```df['comment_text'] = df['comment_text'].apply(clean_text)```.

Antes de retornar a tabela, salvamos a tabela em um arquivo csv atrav√©s do m√©todo ```to_csv()```. Al√©m do nome do arquivo, tamb√©m passamos ```index=False```. Este par√¢metro √© crucial porque o Pandas inclui o √≠ndice como a primeira coluna no arquivo CSV. O par√¢metro index=False instrui o Pandas a N√ÉO salvar essa coluna de √≠ndice no arquivo.